# 100 Days Of ML Code - Activity Log



### Day 0: July 29th, 2018

**Today's Progress**:

Learned about hyperparameter tuning, which entails changing the parameters of a machine learning model, as opposed to making changes to the underlying data.  In this case, was looking at the k-value in a KNN model (see next line).

Worked through exercises to optimize hyperparamters, specifically in a k-nearest-neighbors model (optimizing the k-value by using grid search).

Next, learned about using holdout validation, a process involving splitting your dataset into a 50% train and 50% test set, generating predictions, calculating errors, switching the train and test set, repeating earlier steps, and then averaging your errors.

**Thoughts:** 

The hyperparameter tuning using grid search is pretty quick, easy, and efficient.  I enjoyed learning about it.  However, throughout the exercises, I had to revisit a couple concepts including looping through dictionaries and using the Python built-in function 'enumerate'.

This was my first exposure to holdout validation, which is a pretty handy concept.  I'm looking forward to learning more about this and applying to some other "price prediction" datasets.

**Link to work:** https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day0_knn.py



### Day 1: July 30th, 2018

**Today's Progress**:

Learned about the modules KFold and cross_val_score, both from Python's Scikit-Learn library.  

Worked on completing the Dataquest Machine Learning Fundamentals course by spending an hour on the guided project, Predicting Car Prices.  I will post the completed project once I make it all the way through.  One thing I try to do with most of these guided projects is to create a template that can be used for other similar efforts.

I also signed up for the following Kaggle competition : https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/discussion/62146
And.... the associated Google Cloud ML Course on Coursera: https://www.coursera.org/specializations/machine-learning-tensorflow-gcp?utm_source=googlecloud&utm_medium=institutions&utm_campaign=kaggle_competition_email

Lastly, I worked through Day 9 of HackerRank's '30 Days of Code' challenge.  Today entailed using a simple recursive function to calculate a factorial of an integer.  Powerful technique, simple implementation in Python.  Link is provided below.  

It's going to be a lottttttt to keep up with all of these things over the next 100 days, but I couldn't be more excited to learn and grind.

**Thoughts:** 

One thing I'm consistently reminded of as I go through various exercises and guided projects is how important knowing how to clean your data is.  Data is inherently "unclean" from an analytics perspective, and it takes significant effort to get your dataframe into a format where you COULD apply a machine learning algorithm to it.  I imagine it's a topic I'm going to have to come back to again and again.

**Link to work:** https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day1_factorial.py



### Day 2: July 31st, 2018

**Today's Progress**:

Worked through HackerRank's Day 10 Challenge, counting the maximum number of 1's in a binary representation of some int.  This was a good little challenge, and I took the longer route to ensure I understood every step.  You can see the link to my work below.

I also completed Dataquest's Machine Learning Fundamentals course including a project to predict car prices.  Link to this is also below.

I will wrap up the day by working through some more of Google Cloud's ML Course.

**Thoughts:** 

One of the first things I did today was decided to make a change to my approach in terms of studying.  Although I'm generally putting between 3-4 hours a day, I want to be sure I'm hitting certain things daily.  As such, I'm going to always start my day with a single HackerRank challenge.  That will ensure I always have something that I can share and that I'm getting the coding synapses firing.  After HackerRank, I'll ensure I get at least 1% of my Dataquest Data Scientist Path completed.  Lastly, I'll spend the rest of my time doing the Google Cloud Machine Learning Course and Kaggle Taxi Fare Prediction Competition.

**Link to work:** 
https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day2_binary.py

**Link to work 2 (Dataquest Project):**
https://dananomics.com/portfolio/predicting-car-prices/



### Day 3: August 1st, 2018

**Today's Progress**:
Started the day working through HackerRanks "30 Days of Code" Day 11 challenge on 2D Arrays.  More specifically, the task was to take a 6 x 6 2D array, and find the largest sum of all hourglass shapes.  This was great practice for much of the HackerRank challenges leading up to it, reinforcing the concepts of referencing by index, loops, and finding maximum values.  You can see the link to my solution below.

Next, I dug into Dataquest's Calculus for Machine Learning course, which begins with a discussion of "rate of change" and the concept of a secant line (which I imagine will soon translate to a discussion on tangents and derivatives).

I might get a small amount more than this done today, but will call it a little earlier than usual.  I still got around 2 hours of studying in, which I feel okay about.

**Thoughts:** 
Reflecting on the last few months, and also understanding how I'm approaching things going forward, I can't help but feel extremely optimistic that I've been making good progress and will be making great progress going forward.  It's been a lot of fun to feel certain synapses in my brain fire in new ways and for algorithmic thinking to start seeming more natural.  

In the world of Computer Science, and the exploding disciplines of Data Science and Machine Learning, one of the biggest appeals to me is that you can never master it.  To be fair, you can get really good.  But, just as you're getting really good, technology is still evolving.  New paradigms are coming into existence, new software and hardware stacks, new languages.  It is now and has been evident to me for some time that I never want to stop this journey.  

I'm loving every minute!

**Link to work:** 
https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day3_2dArray.py



### Day 4: August 2nd, 2018

**Today's Progress**:
Started out with Day 12 of HackerRank's "30 Days of Code" challenge, which dealt with class and inheritance.  This is one of those topics, that when you're getting started, seems pretty abstract and can be a little bit challenging to grasp.  However, the power of class inheritance in object-oriented programming cannot be overstated.  Having classes and sub-classes saves you tons of time writing the same functions, methods and the like over and over.  Link to my solution is below.

I'm getting my progress tracking out of the way now, but I do expect to spend another hour working on Dataquest's Linear Algebra for Machine Learning course.  

**Thoughts:** 
Yesterday was a bit of a challenge from a motivational standpoint.  I got through quite a bit of material, but felt like I was having to "bite down on the mouth guard" (to borrow a sports saying) to keep going.  It's important for me to remember that it's okay to have those days, and to have days where I meet my minimal commitment of one hour.  Burnout is a real thing when you're pouring everything you have into something.  I've dealth with it in sports, in academia, and just about every other facet of life.  It's natural, and it passes.  As such, today I'm going to wrap things up at a reasonable time, spend time with my wife, and allow my brain a chance to digest much of the material I've poured into it over the last week or so. 

**Link to work:** 
https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day4_inheritance.py



### Day 5: August 3rd, 2018

**Today's Progress**:
Today, I kicked things off with HackerRank's Day 12 of the 30 Days of Code.  The challenge today had to do with Abstract Classes, which involves creating a class, that cannot be instantiated, but whose properties and methods are then extended to a subslcass, which can be instantiated (say, what?!)  See thoughts below in "Thoughts" section.

Next, I continued working on Dataquest's Linear Algebra for Machine Learning course.  Specifically, worked on getting matrices into row reduced echelon form (1's along diagonal from top left to bottom right and 0's elsewhere), using Gaussian Elimination (leveraging row operations to get matrix into desired form).

I also plan to get some of the Coursera/Google Cloud ML course in over the course of the day.

I'm at 2.5 hours of study so far today, which is a good way to start my morning, and kick off my work day.

**Thoughts:** 
Continuing on with my "say, what?!" comment above, this was a pretty straight-forward challenge for an all-things-not-straight-forward concept.  I had to do quite a bit of reading about the purpose for using an Abstract Base Class (ABC) in Python, and came to this conclusion: the primary goal is to ensure what can be considered certain "standards" on the subclasses.  For example, all attributes and methods must be defined in the subclass.  This can help you avoid overlooking certain things you need your subclass to do.  Really interesting and seemingly valuable concept, primarily when you are coding at scale (many subclasses per ABC).  However, am I missing anything here?  Would love to hear a "layman's terms" explanation of this concept.

With regards to the linear algegbra, I didn't realize how much of this content has slipped my mind over the years since my Mathematical Economics courses.  Revisiting this material really reinforces that how I'm approaching my learning, by going through specializations/tracks, is a great way to do it.  Reason being, even if you have to revisit topics you already "know," this really helps solidify them and serves as a great refresher. 

**Link to work:** 
https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day5_abstractClasses.py



### Day 6: August 4th, 2018

**Today's Progress**:
Got Day 6 of the 100 Days of ML Challenge started with HackerRank's "30 Days of Code" Day 14 Scope challenge.  This challenge involved creating a class method that references instance variables, and computing the maximum difference between any 2 integers in a list.  See "Link to work" below for solution.

Next, dove back into Dataquest's 'Linear Algebra for Machine Learning' course.  Worked with matrix-vector operations, specifically using the numpy.dot method to multiply matrices by vectors.  Finished the day solving systems of equations by using matrix inversion (see "Link to work" below).  If you're familiar with solving systems of equations using this method, you know it's enough to make you want to close your computer and leave the house... (just kidding, sort of)

So, being a nice day here in Denver, that's what I'm going to do.  Cheers everyone.

I'll be back at it tomorrow with a fresh mind and energy.

**Thoughts:** 
Object-oriented programming is a very powerful thing, and can feel a bit overwhelming at times.  Class inheritance, instance and class methods, super(), metaclass... the terms alone are enough to make your head spin.  However, there is one thing that makes me feel better about my ability to thoroughly grasp these concepts over time, and that is, I am leaps and bounds beyond where I was when I started programming, and even from a couple months back.

A saying that I often think of during the more grueling days is from the one and only Dwayne "The Rock" Johnson.  He says, “Success isn’t always about ‘Greatness’, it’s about consistency. Consistent, hard work gains success. Greatness will come.”  I've noticed with anything you are trying to learn and get better at in life, the way you do that is BY SHOWING UP AND BEING ENGAGED.  Even on an off day, you can still watch a video or read an article having to do with whatever it is your trying to learn.

I've mentioned before, that it's been fun to notice certain concepts which once I couldn't grasp become much more palatable over time, and even to where I feel I could explain them to someone else.  The journey is long from over, but it's already been really gratifiying.

**Link to work:** 
1) HackerRank: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day6_scope.py
2) Dataquest: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day6_matrixInversion.py



### Day 7: August 5th, 2018

**Today's Progress**:
For Day 7 of the 100 Days of ML Challenge, I worked on a HackerRank challenge for Linked Lists.  My task was to create an insert method to take a first node (header), create the subsequent nodes, and return a reference to the header. (see "Link to work" below)

Spent a little over an hour working on the problem and reading documntation on how Linked Lists work, and how they are implemented in Python.  

I might cap the day off with some of the Google ML course on Coursera, but that's up in the air at this point.

**Thoughts:** 
At a high level, the concept of a linked list is not a particularly difficult thing to grasp.  Here's the gist... you have a header node, which starts with data and a pointer to any subsequent/ linked nodes.  As each node is added, it similarly has data and pointers to the next nodes.  The last node has data, and null/'None' as a pointer. 

Despite being able to grasp the concept well, I definitely feel like I need to keep reading up on implementation steps and try to find some walkthroughs, so that I thoroughly understand all of the code.  

**Link to work:** 
HackerRank: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day7_linkedList.py



### Day 8: August 6th, 2018

**Today's Progress**:
Kicked of Day 8 of the 100 Days of ML Challenge with more HackerRank.  Specifically, today I was working with exception handling.  The goal was to take a string input provided by HackerRank, convert the string to an integer, and print the converted value.  However, in a case where the value could not be converted, I printed "Bad String."

Next, I spent some time on Dataquest's "Linear Algebra for Machine Learning" course.  Numpy's Linear Algebra (linalg) module was introduced, which makes things like calculating the determinant and inverse of a matrix MUCH quicker and easier than doing it by hand.

I'll cap the day off with a little bit more Dataquest or Coursera's Google ML course.

**Thoughts:** 
Even as a more novice programmer, this was probably the easiest HackerRank challenge I've come across up to this point.  It was pretty refreshing after staring at linked lists and variable scope for the last couple days.

It's great revisiting concepts related to Linear Algebra.  I've always enjoyed learning about mathematical topics, particularly Calculus and Linear Algebra.  I prefer a good optimization problem over a Sudoku or other puzzle most days.  

**Link to work:** 
HackerRank: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day8_exceptionsStrToInt.py



### Day 9: August 7th, 2018

**Today's Progress**:
As has been the case for recent posts, got Day 9 of the 100 Days of ML Code Challenge started with HackerRank.  Today, extended the concept of Exception handling by throwing a custom error message when the parameters to a method do not meet certain criteria (being positive in this case).  

Next, I finished Dataquest's "Linear Algebra for Machine Learning" course.  The end of the course talked about systems that have trivial solutions (zero vector), infinitely many solutions (linearly dependent equations) and no solutions.  The process for solving systems differs whether the matrix is rectangular (must use Gaussian elimination) or square (can use determinant and matrix inversion).  

Link to Certificate: https://www.dataquest.io/view_cert/K7SKI4D947299HQAQ0I3/

Next up was the start of the Linear Regression for Machine Learning course in Dataquest.  Having an Economics background, a lot of this is familiar territory to me.  The course starts with an intro to creating a Linear Regression in Python, and the goal of minimizing the Residual Sum of Squares.

Finishing the day, as usual, with the Google Cloud / Coursera ML course.

**Thoughts:** 
The concept of creating classes and class inheritance is an integral piece of Object-Oriented Programming (OOP). And for those of us who don't have a CS background, and haven't had the pleasure of a professor beating this into our heads for months on end, it's a bit tricky to understand. It's a concept that I've gone back to time and time again, asking questions like, "What is this 'init' thing again? Why am I putting self in this class method? Wait, why am I torturing myself with this again?" (kidding on the last part).

I re-read an article I had seen some time ago again today, from the following link: https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/

The author gives a great breakdown of the intersection between Python as a language and OOP. Give it a read, if you're like me, and still working to solidify those concepts.

**Link to work:** 
HackerRank: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day9_moreExceptions.py



### Day 10: August 8th, 2018

**Today's Progress**:
Once again, got Day 10 of the 100 Days of ML Code Challenge started with HackerRank.  Today, I  dug into Queues and Stacks, which are data structures.  One of the biggest differentiators between the two is that a stack's elements can only be manipulated by Last-In-First-Out (LIFO) and a queue's elements are manipulated by First-In-First-Out (FIFO).

I did some extra reading to ensure I understood these concepts, and found this really useful article: https://medium.com/@kojinoshiba/data-structures-in-python-series-2-stacks-queues-8e2a1703d67b

The following Python documentation I also found really useful: https://docs.python.org/2/tutorial/datastructures.html

I spent a couple hours on the above this morning, working to wrap my head around how these data structures work and their implementation in Python.

I'm also going to continue on with Dataquest's Linear Regression for Machine Learning course and the Google Cloud ML course on Coursera.

**Thoughts:** 
One thing I've been extremely thankful for is diving into these HackerRank challenges every morning.  Having been trained as an Economist, there are a number of Machine Learning concepts that come pretty naturally/ easily (optimization, minimizing errors, calculus, statistics, linear algebra, etc.).  However, something that most of us from Statistics and Economics backgrounds lack is the formal Data Structures and Algorithms training.  I feel I'm growing a lot by forcing myself to think through these things on a daily basis.  It's not a practice I plan on stopping.  Coupling this with the Data Science education I'm getting online seems to be a really good recipe for success.  Of course, there is a long way to go, but I'm feeling optimistic about all of it.

**Link to work:** 
HackerRank: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day10_queuesAndStacks.py



### Day 11: August 9th, 2018

**Today's Progress**:
Day 11 of the 100 Days of Machine Learning Code Challenge started with more... you guessed it... HackerRank.  Today's challenge had to do with Interfaces.  An interface, in practice, is very similar to an Abstract Class (set of rules, specs, methods for related Classes to use).  However, after doing some digging, I realized that Interfaces are not really "a thing" in Python.  Python has the benefit of allowing multiple inheritance, which I understand is the primary use for Interfaces in say, Java.  As such, my solution really just involved implementing a class method "Calculator" (which was an instance of another class "Advanced Arithmetic").  Check out the link to the solution below in the "Link to work."

It's probably also worth noting that for the last couple nights, I've been working through Coursera's Google ML course, which has been pretty awesome.  Learning about how such an incredible company with so much influence approaches Machine Learning is really beneficial.  I've seen course sections devoted to Machine Learning workflow, model bias (which surprisingly was being taught by my college roommate... REALLY COOL!), and last night, got to look at Qwiklabs, which is an IDE for analytics in Google Cloud.

**Thoughts:** 
Short on thoughts today, but ultimately, I'll just say that this challenge has been extremely fun and gratifying.  Getting to interact with the Data Science and Machine Learning communities, learning that there are so many other people out there who aim to change themselves in order to help change the world, I feel extremely thankful.  I can't wait to see how my skill set and network of similar-minded people evolves over the next 90 days.  Thank you to everybody who are out there, learning, contributing, and helping each other get better!

**Link to work:** 
HackerRank: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day11_interfaces.py



### Day 12: August 10th, 2018

**Today's Progress**:
Day 12's HackerRank challenge of the day had to do with bubble sort, a sorting algorithm that takes each item in an array, and if the next item is bigger, swaps the two.  The result is that each item "bubbles" to it's respective place in the array.  After each item is iterated through in this way, you have a sorted array.

If you haven't seen it, check out this video of Eric Schmidt of Google asking Obama about which algorithm to use for a specific sorting problem (hint: it's not bubble sort):

https://www.youtube.com/results?search_query=bubble+sort+obama

I'm also going to work on more of the Linear Regression for Machine Learning course in Dataquest.

**Thoughts:** 
A topic that's come up quite a bit recently in posts, and in conversations with the Data Science community on LinkdeIn, is whether the focal point for the budding data scientist should be learning or doing.  That is, should you be focused on the knowledge acquisition or working on projects and building things. 

This is something I think a lot about, and I know many of us struggle with where the balance should be.

Here is how I'm approaching things....

Currently, I'm focusing 90% on knowledge and 10% on projects.  I plan to continue this until I'm through all of the Dataquest material.  Reason being, I want to have a good foundational knowledge on which to lean.  Then, as I'm going through a project, I'm spending less time scratching my head, and more time referring back to things I've learned (or leveraging Stack Overflow and actually knowing what to ask).

Once I finish Dataquest, I plan to switch gears and be closer to 50% knowledge and 50% projects.  More specifically, I will try to apply everything I'm learning to working with a dataset that I'm interested in and hopefully coming up with an ML "solution" to a problem.

Over time, as I reach a good level of knowledge saturation, most of my efforts will be directed at projects, and I'll take courses primarily as refreshers or to learn things I haven't been exposed to.

**Link to work:** 
HackerRank: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day12_bubbleSort



### Day 13: August 11th, 2018

**Today's Progress**:
Kicked today off on HackerRank learning about Generics.  Generics are a way that you can parameterize your datatypes in some programming languages, although it isn't particularly applicable to Python.  Reason being, Python is dynamically typed rather than statically typed.  In a statically typed language, you have to define the datatype of a variable.  Python determines the datatype for you by looking at the data with a paradigm called "duck typing," named based on the phrase "if it walks like a duck and quacks like a duck, it's a duck."  In order to get through to the next challenge, I looked at some of the Java solutions in the discussions and submitted one.

Because I didn't get to work through a coding exercise on the above, I jumped into the next HackerRank challenge on Binary Search Trees (BST).  In a BST, the element in each left subtree is smaller than it's parent node, and the element in the right subtree is larger than the parent node.  You can see the tutorial here (https://www.hackerrank.com/challenges/30-binary-search-trees/tutorial) for a better understanding.  This is a really handy search algorithm that has wide-ranging applications, and is valuable as an efficient way to find out whether items are related, and the distance between them.

I also spent some more time on Dataquest's Linear Regression for Machine Learning course, which I will hopefully be able to wrap up tomorrow.  The focus in this course today was on determining the appropriate features to include in your model, by understanding the correlation between the features and target variable, and across the features themselves.

**Thoughts:** 
Both of the HackerRank challenges above were really tough, and I did have to do some scouring of the discussions and StackOverflow to get an understanding of some of the ways to implement them.  Although it's frustrating to not grasp these concepts right off the bat sometimes, I acknowledge that self-teaching data structures and algorithms is challenging in and of itself.  If I keep at it, like anything else, these concepts will become more manageable over time.

**Link to work:** 
HackerRank: https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day13_binarySearchTrees.py



### Day 14: August 12th, 2018

**Today's Progress**:
Today I worked on HackerRank's Day 23 (of 30 Days of Code challenge), involving Level-Order traversal.  Level-order traversal is where you start at the root of a binary tree, and traverse the tree by going to each of the child subtrees sequentially, from left to right (you visit each level of the tree in order).

I also worked some on the Linear Regression for Machine Learning course in Dataquest.

**Thoughts:** 
Today was one of the first days that I legitimately could not figure out a solution to this problem.  Even on days where I've looked around at different approaches, I always want to make sure that I could get to the solution I'm leveraging in creating my own.  Today, unfortunately, was not one of those days.  As such, I'm not posting a solution until I can fully understand how it works.  

I definitely feel like the last few days of the HackerRank challenges have tested my resilience and been a bit discouraging.  However, this is where the biggest gains come from.  The moment you have to tap into your grittiness to break through a perceived plateau is a great thing.  

I'm going to keep reading through documentation on Queues, Binary Trees, and Level-Order Traversal until I understand these concepts.  I'm also going to try and leverage the community on LinkdeIn to see if I can find some good resources to help get over this hump.

**Link to work:** 
None today, unfortunately.



### Day 15: August 13th, 2018

**Today's Progress**:
Today I spent around an hour and a half looking at different resources on Binary Trees and Traversal methodologies.  All in all, I kept it light and am giving myself an opportunity to rest and re-energize.

**Thoughts:** 
Over the coming couple days, I'll spend a little bit of time each day learning more about Data Structures and trying to get over the hump of where I'm currently stuck.  However, I'll focus more on the Data Science oriented learning, rather Computer Science.  Hopefully, giving my brain a chance to internalize the Data Structure material will help me connect with it in a way that I haven't been able to up to this point.  

A lot of the above was advice from the Data Science community on LinkedIn, who have been awesome to get to know and are always supportive.  Thanks to all of those who offered said support.

**Link to work:** 
None



### Day 16: August 14th, 2018

**Today's Progress**:
Today I did a little bit more work on the Coursera/ Google Cloud ML course, and spent some time learning about algorithms via Mike Bostock's post "Visualizing Algorithms."  Keeping this week a little bit lighter than normal, but acquiring knowledge either way.

**Thoughts:** 
It was really nice to take a bit of a break over the last couple days.  At times, it's easy to burn out and to forget that what we are doing in trying to learn new material can be hard.  And that's okay.  It's all about the perseverance to keep going, the humility to leverage resources in the community, and the curiosity that keeps you happy on the journey.  Sometimes it's probably useful to break things up, to seek out new answers in the greater journey toward learning Data Science.  And in the end, those things that feel like a struggle will likely present themselves in a more digestible manner.

**Link to work:** 
None, but definitely check out the following link, which is pretty helpful in understanding algorithms: https://bost.ocks.org/mike/algorithms/



### Day 17: August 15th, 2018

**Today's Progress**:
Day 17 of the 100 Days of ML Code Challenge involved some more learning in Coursera's Google Cloud ML course.  Overall, some really intriguing and fun material.  The course demonstrated how you can use a high-powered virtual machine to do some of the heavy lifting for you, and then you can take a somewhat aggregated dataset and work with it in a hosted notebook environment (with a look and feel of Jupyter).  I worked through this workflow in a couple different labs, including one on hosting Earthquake data and another on analyzing flight delays.

**Thoughts:** 
It's interesting to see how advanced and/or modern technologies can make seemingly arduous tasks relatively simple.  Being exposed to the Google Cloud environment seems to be indicative of a soon-to-be world where Artificial Intelligence and Machine Learning solutions are not only ubiquitous in their accessibility, but are relatively easy to implement without formal training in these types of technologies.  It was a reminder of how much I enjoy this stuff, and that I don't "always" need to bog myself down in minutia.

**Link to work:** 
None



### Day 18: August 16th, 2018

**Today's Progress**:
Today, I spent hours and hours and hours digging back into Binary Trees, reading different articles to understand their construction, how to print them, how to traverse them, and why the heck I was stuck.  When I realized that my major sticking point was certain recursive functions, that's where I went next.

Below are a couple links I was digging into:

https://www.tutorialspoint.com/python/python_tree_traversal_algorithms.htm

https://www.tutorialspoint.com/python/python_binary_tree.html

https://www.youtube.com/watch?v=aM-oswPn19o

**Thoughts:** 
As mentioned above, today I realized why I've struggled with a lot of the concepts around Binary Trees, and a lot of it has to do with them being a recursive structure.  Being from a non-Computer Science background, recursion can be a tricky concept to fully internalize.  Of course, there are cases where it's not particularly difficult, such as a factorial, summation, or even FizzBuzz, but when you're talking about traversing tree structures, where there are multiple recursive steps, I haven't quite had the "ah hah" moment.  I've taken in a lot of this information this week, and I think for the next few days I'll focus back on the Data Science material (Dataquest and Coursera/Google ML) and give that part of my brain a quick break.  Sunday or Monday I can get back into the weeds and try to dig myself out.

**Link to work:** 
None



### Day 19: August 17th, 2018

**Today's Progress**:
Today, I dug back into Dataquest's Data Science path, continuing the "Linear Regresssion for Machine Learning" course (see 'Link to work' below), diving into Gradient Descent and Ordinary Least Squares estimation.  This evening I'll get a bit more done in this course, with the hopes of finishing all except the Guided Project, which I'll tackle this weekend.

To ensure I understood Gradient Descent, I read a couple articles to solidify the concepts:
https://towardsdatascience.com/gradient-descent-simply-explained-1d2baa65c757
https://www.pyimagesearch.com/2016/10/10/gradient-descent-with-python/

**Thoughts:** 
Here we are, about 1/5th of the way through the 100 Days of ML Code Challenge.  One thing that's been great about the journey so far is that I've learned a lot about myself, my limitations, and generally have become a better programmer.  My hope is that toward the end of this challenge, I can really switch gears and start focusing more on project-related work, and build some cool stuff.  It's been extremely fun, challenging and really tested my persistence.  I'll finish the challenge better for it!

**Link to work:** 
https://github.com/danahagist/100_Days_Of_ML_Code/blob/master/day19_housingLinearRegression.py



### Day 20: August 18th, 2018

**Today's Progress**:
Today, I started out with Coursera/ Google's "How Google Does Machine Learning" course and completed that course. Here is the link to my certificate:
https://www.coursera.org/account/accomplishments/verify/E79A49DSA8MX

Then, I dove into the next course in the specialization, called "Launching into Machine Learning." I plan to spend another hour this evening working on this course, which is really interesting, and presented in a digestible way.

I also played a little bit with Binary Tree Traversal Algorithms on a whiteboard for practice purposes.

**Thoughts:** 
Interestingly, although I've left the material on Binary Search Trees "somewhat alone" over the last few days, I've still found myself understanding them more and more with each passing day.  Yesterday, I bought a whiteboard so that I could practice writing out algorithms in an interview-esque setting.  Having heard advice from my fellow Data-Science folks on LinkdeIn about the Feynman technique (thanks Sanwal), I started thinking about these algorithms as if I had to teach them to someone else.  This has helped me immensely in understanding where I'm stuck and where my focus needs to be.  In case you're wondering, the slight sticking point right now is having a multiple recursive case algorithm where once the base case is satisfied, the output/return is feeding going back to the prior step (i.e. making it's way back up the tree).  In any event, I'm confident that the clicking moment is somewhere close, even if it feels just barely out of reach at the moment.

**Link to work:** 
None (but see link to certification above)



### Day 21: August 19th, 2018

**Today's Progress**:
Today, I continued with Coursera/ Google's "Machine Learning with TensorFlow on Google Cloud Platform Specialization", specifically moving into the course "Launching into Machine Learning." Topics of the day included the history on a number of popular Machine Learning algorithms like decision trees, random forests, linear regression, perceptrons and neural networks.  Also, I looked at loss functions and gradient descent, as an alternative to Ordinary Least Squares when the data is too big (which would be computationally expensive).

**Thoughts:** 
I feel like I really got an opportunity today to solidify some concepts and have fun.  It's not always the case that these days of studying and learning are particularly enjoyable, so one thing I need to keep in mind is to seek balance (as in all things).  In other words, if I'm feeling really bogged down on a particular topic, I can leave that thing alone and dive into something else.  It's almost always easier to come back to something with a fresh mind rather than just trying to "stick it out" with a frustrated mind. The body of knowledge in this field is endless, so there's no use in sitting with a topic that isn't resonating with you at that moment.  

**Link to work:** 
None




### Day 22: August 20th, 2018

**Today's Progress**:
Today, I continued on with Dataquest's course on "Linear Regression for Machine Learning."  I got through all of the learning material for the course.  Today's topics primarily included Ordinary Least Squares (as a way to minimize the loss function), Gradient Descent (when data is too big for OLS to be computationally feasible) and Processing and Transforming Features.  The Guided Project coming up is on "Predicting House Sale Prices," and I plan to dive into that this evening for a couple hours, making as much progress as I can.

**Thoughts:** 
I'm excited for this Guided Project and to work this Machine Learning solution from start to finish.  I've done quite a few Linear Regression analyses in R, but not thoroughly in Python.  All of the material at this point in the course is a lot of fun to work with, so I am able to approach each day with a strong sense of motivation and fulfillment.

**Link to work:** 
None, but will include Guided Project once that is complete.
